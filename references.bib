@Manual{example,
    title = {example referance},
    author = {Firstname Lastname},
    year = {1900},
}

@article{Kunc2024,
  author    = {V. Kunc and J. Kléma},
  title     = {Three Decades of Activations: A Comprehensive Survey of 400 Activation Functions for Neural Networks},
  journal   = {arXiv},
  year      = {2024},
  volume    = {arXiv:2402.09092},
  doi       = {10.48550/ARXIV.2402.09092}
}

@article{Vaswani2017,
  author    = {A. Vaswani and Others},
  title     = {Attention Is All You Need},
  journal   = {arXiv},
  year      = {2017},
  month     = {Dec},
  day       = {06},
  volume    = {arXiv:1706.03762v5},
  url       = {http://arxiv.org/abs/1706.03762v5}
}

@article{Lee2023,
  author    = {M. Lee},
  title     = {GELU Activation Function in Deep Learning: A Comprehensive Mathematical Analysis and Performance},
  journal   = {arXiv},
  year      = {2023},
  month     = {Aug},
  day       = {01},
  volume    = {arXiv:2305.12073},
  doi       = {10.48550/arXiv.2305.12073}
}

@article{Shazeer2020,
  author    = {N. Shazeer},
  title     = {GLU Variants Improve Transformer},
  journal   = {arXiv},
  year      = {2020},
  month     = {Feb},
  day       = {12},
  volume    = {arXiv:2002.05202},
  doi       = {10.48550/arXiv.2002.05202}
}

@article{Samuel2023,
  author    = {D. Samuel and A. Kutuzov and L. Øvrelid and E. Velldal},
  title     = {Trained on 100 million words and still in shape: BERT meets British National Corpus},
  journal   = {arXiv},
  year      = {2023},
  month     = {May},
  day       = {05},
  volume    = {arXiv:2303.09859},
  doi       = {10.48550/arXiv.2303.09859}
}

@article{Liu2024,
  author    = {Z. Liu and Others},
  title     = {KAN: Kolmogorov-Arnold Networks},
  journal   = {arXiv},
  year      = {2024},
  month     = {May},
  day       = {02},
  volume    = {arXiv:2404.19756},
  doi       = {10.48550/arXiv.2404.19756}
}

@misc{Rajanand,
  author    = {A. Rajanand and P. Singh},
  title     = {ErfReLU: Adaptive Activation Function for Deep Neural Network}
}

@article{Mirzadeh2023,
  author    = {I. Mirzadeh and Others},
  title     = {ReLU Strikes Back: Exploiting Activation Sparsity in Large Language Models},
  journal   = {arXiv},
  year      = {2023},
  month     = {Oct},
  day       = {06},
  volume    = {arXiv:2310.04564},
  doi       = {10.48550/arXiv.2310.04564}
}