% Comparisons
% Gelu (baseline) with Adaptive gelu
% ReLU with PReLU (Adaptive reslu)
% SiLU with Swish
% ReLU with GeLu
\section{Results} % PAST TENSE!!!
\label{sec:results}
\textbf{ToDo: Fix the position of all those tables bellow.}
All results of evaluations on BLiMP and GLUE datasets are shown in Table \ref{table:all-results}.\\
After performing bootstrap resampling for 10,000 samples, we calculated the mean difference and confidence interval to make each of the comparisons mentioned in section \ref{sec:experimental_setup}.\\
Comparison of the Baseline (GELU) model with the Adaptive GELU model showed that the mean difference is negative for both BLiMP and GLUE benchmarks, showing that the Adaptive GELU model performed slightly better than the Baseline (GELU) model. However, the confidence intervals for both benchmarks contain zero, which means that the difference is not statistically significant. The results are shown in Table \ref{tab:comparison}.\\\\
Boostrap comparing static activations ReLU and SiLU with their adaptive counterparts PReLU and Swish showed that the mean difference is positive for both BLiMP and GLUE benchmarks, showing that the static activation functions performed slightly better than the adaptive activation functions. However, the confidence intervals for both benchmarks contain zero, which means that the difference is not statistically significant. The results are shown in Table \ref{tab:comparison-static-adaptive}.\\\\
The highest GLUE score was achieved by the BERT-KAN model with 63.65, and the highest BLiMP score was achevied by the GPT-KAN model with 63.43. \textbf{ToDo: Further discuss after all statistical tests are done.}\\\\
Across all models, the training times were relatively consistent, with two outliers: KAN network models and ReLU models. The prolonged training time for the ReLU models might be attributed to the busy DelftBlue nodes, whereas the extended time for the KAN models is expected. We will compute the standard deviations for all models once we obtain all the results. Excluding the two outliers, the standard deviation in training times was 3 minutes and 33 seconds.

%Please add the following packages if necessary:
%\usepackage{booktabs, multirow} % for borders and merged ranges
%\usepackage{soul}% for underlines
%\usepackage[table]{xcolor} % for cell colors
%\usepackage{changepage,threeparttable} % for wide tables
%If the table is too wide, replace \begin{table}[!htp]...\end{table} with
%\begin{adjustwidth}{-2.5 cm}{-2.5 cm}\centering\begin{threeparttable}[!htb]...\end{threeparttable}\end{adjustwidth}
\begin{table*}[!htp]\centering
    \caption{Generated by Spread-LaTeX}\label{tab: }
    \scriptsize
    \begin{tabular}{lrrrrrr}\toprule
    Model &Glue Mean &95\% CI &Blimp Mean &95\% CI Blimp &Avg. Train. Time \\\cmidrule{1-6}
    BERT Baseline (GELU) &56,04 &[52.35, 58.74] &58,48 &[56.68, 59.5] &1h 41m 27s ± 32s \\\cmidrule{1-6}
    BERT Learnable GELU &57,69 &[56.75, 58.73] &59,25 &[58.78, 59.65] &1h 47m 56s ± 313s \\\cmidrule{1-6}
    GPT Baseline (GELU) &58,95 &[58.27, 59.7] &57,82 &[56.97, 58.68] &1h 42m 41s ± 103s \\\cmidrule{1-6}
    GPT Learnable GELU &59,3 &[58.92, 59.73] &57,24 &[56.47, 58.03] &1h 41m 59s ± 102s \\\cmidrule{1-6}
    BERT ReLU &57,91 &[56.98, 58.87] &58,4 &[57.37, 59.23] &2h 25m 23s ± 147s \\\midrule
    BERT PReLU &N/A &N/A &N/A &N/A &N/A \\
    GPT ReLU &59,41 &[59.0, 59.82] &56,91 &[55.93, 57.8] &2h 20m 27s ± 203s \\
    GPT PReLU &N/A &N/A &N/A &N/A &N/A \\
    BERT SiLU &57,54 &[57.15, 58.1] &59,16 &[58.75, 59.53] &1h 43m 50s ± 268s \\
    BERT Swish &N/A &N/A &N/A &N/A &N/A \\
    GPT SiLU &59,05 &[58.4, 59.63] &57,25 &[56.43, 58.2] &1h 39m 7s ± 270s \\
    GPT Swish &N/A &N/A &N/A &N/A &N/A \\
    GPT KAN &N/A &N/A &N/A &N/A &N/A \\
    \bottomrule
    \end{tabular}
    \end{table*}
\newpage