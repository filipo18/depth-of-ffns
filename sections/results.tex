% Comparisons
% Gelu (baseline) with Adaptive gelu
% ReLU with PReLU (Adaptive reslu)
% SiLU with Swish
% ReLU with GeLu
\section{Results} % PAST TENSE!!!
\label{sec:results}
\textbf{ToDo: Fix the postition of all those tables bellow.}
All results of evaluations on BLiMP and GLUE datasets are shown in Table \ref{table:all-results}.\\
After performing bootstrap resampling for 10 000 samples, we calculated the mean difference and confidence interval to make each of the comparisons mentioned in section \ref{sec:experimental_setup}.\\
Comparison of Baseline (GELU) model with Adaptive GELU model showed that the mean difference is negative for both BLiMP and GLUE benchmarks, showing that the Adaptive GELU model performed slightly better than the Baseline (GELU) model. However the confidence intervals for both benchmarks contain zero, which means that the difference is not statistically significant. The results are shown in Table \ref{tab:comparison}.\\\\
Boostrap comparing static activations ReLU and SiLU with their adaptive counterparts PReLU and Swish showed that the mean difference is positive for both BLiMP and GLUE benchmarks, showing that the static activation functions performed slightly better than the adaptive activation functions. However the confidence intervals for both benchmarks contain zero, which means that the difference is not statistically significant. The results are shown in Table \ref{tab:comparison-static-adaptive}.\\\\
The highest GLUE score was achieved by the BERT-KAN model with 63.65, the highest BLiMP score was achevied by the GPT-KAN model with 63.43. \textbf{ToDo: Further discuss after all statistical tests are done.}\\\\
Across all models, the training times were relatively consistent, with two outliers: KAN network models and ReLU models. The prolonged training time for the ReLU models might be attributed to the busy DelftBlue nodes, whereas the extended time for the KAN models is expected. We will compute the standard deviations for all models once we obtain all the results. Excluding the two outliers, the standard deviation in training times was 3 minutes and 33 seconds.
\textbf{ToDO: Add results of other comparisons. (evaluations still running on DelftBlue)}

\begin{table}[h]
    \centering
    \begin{tabular}{|l|c|c|}
    \hline
     & \textbf{Blimp} & \textbf{Glue} \\ \hline
    \textbf{Mean difference} & -0.135 & -0.878 \\ \hline
    \textbf{Confidence intervals} & $[-1.16, 0.636]$ & $[-2.674, 0.604]$ \\ \hline
    \end{tabular}
    \caption{Mean differences of combined GPT-Neo and RoBERTa scores for Basline (GELU) and Adaptive (GELU) models}
    \label{tab:comparison}
\end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{|l|c|c|}
    \hline
     & \textbf{Blimp} & \textbf{Glue} \\ \hline
    \textbf{Mean difference} & 0.442 & 1.355 \\ \hline
    \textbf{Confidence intervals} & $[-1.85,  2.3]$ & $[-0.35,  3.05]$ \\ \hline
    \end{tabular}
    \caption{Mean differences of combined GPT-Neo and RoBERTa scores for Static and Adaptive activation functions.}
    \label{tab:comparison-static-adaptive}
\end{table}

\begin{table}[!htp]\centering
    \scriptsize
    \begin{tabular}{lrrrrr}\toprule
    \textbf{Model} &\textbf{Seed} &\textbf{Blimp} &\textbf{Glue} &\textbf{Time} \\\cmidrule{1-5}
    BERT Baseline GELU &42 &54.94 &49.22 & \\
    BERT Baseline GELU &2 &59.5 &59.9 &1h 41m 32s \\
    BERT Baseline GELU &3 &59.6 &56.6 &1h 41m 4s \\
    BERT Baseline GELU &4 &59.3 &57 &1h 41m 5s \\
    BERT Baseline GELU &5 &59.1 &57.5 &1h 42m 21s \\
    GPT Baseline GELU &42 &59.05 &58.22 & \\
    GPT Baseline GELU &1 &58 &58.5 &1h 43m 35s \\
    GPT Baseline GELU &2 &56.6 &57.8 &1h 45m 19s \\
    GPT Baseline GELU &3 &56.6 &59.1 &1h 41m 44s \\
    GPT Baseline GELU &4 &59.2 &60.5 &1h 40m 12s \\
    GPT Baseline GELU &5 &57.4 &59.6 &1h 42m 32s \\
    BERT Adaptive GELU &42 &59.4 &57.1 &1h 58m 39s \\
    BERT Adaptive GELU &1 &59.8 &56.2 &1h 45m 56s \\
    BERT Adaptive GELU &2 &59.3 &59.7 &1h 45m 55s \\
    BERT Adaptive GELU &3 &59 &57 &1h 45m 35s \\
    BERT Adaptive GELU &4 &58.2 &57 &1h 45m 56s \\
    BERT Adaptive GELU &5 &59.8 &59.2 &1h 45m 39s \\
    GPT Adaptive GELU &42 &56.8 &60.2 &1h 43m 41s \\
    GPT Adaptive GELU &1 &56.3 &58.8 &1h 41m 26s \\
    GPT Adaptive GELU &2 &57.4 &58.7 &1h 42m 53s \\
    GPT Adaptive GELU &3 &58.7 &59.6 &1h 41m 11s \\
    GPT Adaptive GELU &4 &56 &59.2 &1h 41m 27s \\
    GPT Adaptive GELU &5 &58.3 &59.3 &1h 41m 19s \\
    \toprule \textbf{Other models (not evaluated on multiple seeds yet) } & & & & \\ \midrule
    BERT ReLU &42 &58.5 &57.2 &2h 24m 46s \\
    BERT PReLU &42 &57 &57.6 &1h 47m 27s \\
    GPT ReLU &42 &56.6 &59.9 &2h 17m 4s \\
    GPT PReLU &42 &59.2 &56.1 &1h 42m 28s \\
    BERT SiLU &42 &58.3 &57.5 &1h 45m 4s \\
    BERT Swish &42 &58 &57.8 &1h 43m 8s \\
    GPT SiLU &42 &56.3 &59.9 &1h 39m 35s \\
    GPT Swish &42 &53.7 &57.6 &1h 39m 22s \\
    BERT KAN &42 &56.69 &63.65 &2h 52m 11s \\
    GPT KAN &42 &63.43 &48.8 &3h 23m 35s \\
    \bottomrule
    \end{tabular}
    \caption{All evaluation results}\label{table:all-results}
\end{table}

\begin{table}[h!]
    \centering
    \begin{tabular}{|l|c|}
    \hline
    \textbf{Model Name} & \textbf{Training Time} \\ \hline
    GPT Baseline GELU & 1h 42m 41s $\pm$ 1m 43s \\ \hline
    BERT Baseline GELU & 1h 41m 27s $\pm$ 32s \\ \hline
    BERT Adaptive GELU & 1h 47m 56s $\pm$ 5m 13s \\ \hline
    GPT Adaptive GELU & 1h 41m 59s $\pm$ 1m 02s \\ \hline
    GPT-ReLU & 2h 17m 4s \\ \hline
    BERT-ReLU & 2h 24m 46s \\ \hline
    BERT-Swish & 1h 43m 8s \\ \hline
    GPT-Swish & 1h 39m 22s \\ \hline
    BERT-PReLU & 1h 47m 27s \\ \hline
    GPT-PReLU & 1h 42m 28s \\ \hline
    KAN2-GPT & 3h 23m 35s \\ \hline
    BERT-kan2 & 2h 52m 11s \\ \hline
    GPT-SiLU & 1h 39m 35s \\ \hline
    BERT-SiLU & 1h 45m 4s \\ \hline
    \end{tabular}
    \caption{Mean training times with standard deviations ToDo: add other SDs and mean times when other evaluations complete.}
    \label{tab:training-times}
\end{table}
\newpage