# Recap week 6
- [x] fix the space issue on delft blue finish evaluations
- [x] implemenet and train parametric GEGLU and GELU
- [x] work on draft V1, write results, start discusion, revise the other sections
- [x] start surverying interpretability literature (check zotero common for ideas, start from tiny stories) (not part of the project anymore)
- [x] read The Low-Rank Simplicity Bias in Deep Networks (?) (not part of the project anymore)
- [x] finish evals for static activations, swish, prelu, kan
- [x] train learnable/parametric GELU with 5 new seeds
- [ ] implement and train learnable/parametric GEGLU with 5 new seeds (moved to next week)

# ToDo week 7
- [ ] implement and train learnable/parametric GEGLU with 5 new seeds (moved to next week)
- [ ] write responsible research part
- [ ] train learnable geglu with 5 new seeds
- [ ] train geglu with 5 new seeds
- [ ] evaluate all geglu and learnable geglu models 
- [ ] do statistical analysis for geglu, learnable geglu and learnable gelu.